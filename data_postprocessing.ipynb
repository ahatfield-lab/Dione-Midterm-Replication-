{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping /Users/huxiyan/Desktop/H/25Fall/COSC426/Dione-Midterm-Replication-/results/XLM-R/fon_ibo_results_bytokentype.tsv, missing expected columns.\n",
      "Skipping /Users/huxiyan/Desktop/H/25Fall/COSC426/Dione-Midterm-Replication-/results/XLM-R/fon_kin_results_bytokentype.tsv, missing expected columns.\n",
      "Skipping /Users/huxiyan/Desktop/H/25Fall/COSC426/Dione-Midterm-Replication-/results/XLM-R/fon_sna_results_bytokentype.tsv, missing expected columns.\n",
      "Skipping /Users/huxiyan/Desktop/H/25Fall/COSC426/Dione-Midterm-Replication-/results/XLM-R/ibo_ibo_results_bytokentype.tsv, missing expected columns.\n",
      "Skipping /Users/huxiyan/Desktop/H/25Fall/COSC426/Dione-Midterm-Replication-/results/XLM-R/kin_kin_results_bytokentype.tsv, missing expected columns.\n",
      "Skipping /Users/huxiyan/Desktop/H/25Fall/COSC426/Dione-Midterm-Replication-/results/XLM-R/all_ibo_results_bytokentype.tsv, missing expected columns.\n",
      "Skipping /Users/huxiyan/Desktop/H/25Fall/COSC426/Dione-Midterm-Replication-/results/XLM-R/sna_sna_results_bytokentype.tsv, missing expected columns.\n",
      "Skipping /Users/huxiyan/Desktop/H/25Fall/COSC426/Dione-Midterm-Replication-/results/XLM-R/all_sna_results_bytokentype.tsv, missing expected columns.\n",
      "Skipping /Users/huxiyan/Desktop/H/25Fall/COSC426/Dione-Midterm-Replication-/results/XLM-R/all_kin_results_bytokentype.tsv, missing expected columns.\n",
      "Skipping /Users/huxiyan/Desktop/H/25Fall/COSC426/Dione-Midterm-Replication-/results/AfroLM/fon_ibo_results_bytokentype.tsv, missing expected columns.\n",
      "Skipping /Users/huxiyan/Desktop/H/25Fall/COSC426/Dione-Midterm-Replication-/results/AfroLM/fon_kin_results_bytokentype.tsv, missing expected columns.\n",
      "Skipping /Users/huxiyan/Desktop/H/25Fall/COSC426/Dione-Midterm-Replication-/results/AfroLM/fon_sna_results_bytokentype.tsv, missing expected columns.\n",
      "Skipping /Users/huxiyan/Desktop/H/25Fall/COSC426/Dione-Midterm-Replication-/results/AfroLM/ibo_ibo_results_bytokentype.tsv, missing expected columns.\n",
      "Skipping /Users/huxiyan/Desktop/H/25Fall/COSC426/Dione-Midterm-Replication-/results/AfroLM/kin_kin_results_bytokentype.tsv, missing expected columns.\n",
      "Skipping /Users/huxiyan/Desktop/H/25Fall/COSC426/Dione-Midterm-Replication-/results/AfroLM/all_ibo_results_bytokentype.tsv, missing expected columns.\n",
      "Skipping /Users/huxiyan/Desktop/H/25Fall/COSC426/Dione-Midterm-Replication-/results/AfroLM/sna_sna_results_bytokentype.tsv, missing expected columns.\n",
      "Skipping /Users/huxiyan/Desktop/H/25Fall/COSC426/Dione-Midterm-Replication-/results/AfroLM/all_sna_results_bytokentype.tsv, missing expected columns.\n",
      "Skipping /Users/huxiyan/Desktop/H/25Fall/COSC426/Dione-Midterm-Replication-/results/AfroLM/all_kin_results_bytokentype.tsv, missing expected columns.\n",
      "Summary table saved to /Users/huxiyan/Desktop/H/25Fall/COSC426/Dione-Midterm-Replication-/results/summary_accuracy.csv\n",
      "     Model Train_Lang Test_Lang  Accuracy\n",
      "0    XLM-R        kin       kin  0.890826\n",
      "1    XLM-R        sna       sna  0.795112\n",
      "2    XLM-R        all       kin  0.935923\n",
      "3    XLM-R        all       ibo  0.756303\n",
      "4    XLM-R        all       sna  0.843738\n",
      "5    XLM-R        ibo       ibo  0.722081\n",
      "6    XLM-R        fon       ibo  0.386593\n",
      "7    XLM-R        fon       kin  0.442289\n",
      "8    XLM-R        fon       sna  0.419451\n",
      "9   AfroLM        kin       kin  0.950262\n",
      "10  AfroLM        sna       sna  0.868760\n",
      "11  AfroLM        all       kin  0.968824\n",
      "12  AfroLM        all       ibo  0.778192\n",
      "13  AfroLM        all       sna  0.884625\n",
      "14  AfroLM        ibo       ibo  0.776145\n",
      "15  AfroLM        fon       ibo  0.318194\n",
      "16  AfroLM        fon       kin  0.356794\n",
      "17  AfroLM        fon       sna  0.319360\n",
      "\n",
      " LaTeX table saved to /Users/huxiyan/Desktop/H/25Fall/COSC426/Dione-Midterm-Replication-/results/summary_accuracy_table.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "base_dir = \"/Users/huxiyan/Desktop/H/25Fall/COSC426/Dione-Midterm-Replication-/results\"\n",
    "output_csv = os.path.join(base_dir, \"summary_accuracy.csv\")\n",
    "\n",
    "rows = []\n",
    "\n",
    "for model_name in os.listdir(base_dir):\n",
    "    model_path = os.path.join(base_dir, model_name)\n",
    "    if not os.path.isdir(model_path):\n",
    "        continue\n",
    "\n",
    "    for file_name in os.listdir(model_path):\n",
    "        if not file_name.endswith(\".tsv\"):\n",
    "            continue\n",
    "\n",
    "        file_path = os.path.join(model_path, file_name)\n",
    "\n",
    "        parts = file_name.replace(\"_results_bycond.tsv\", \"\").split(\"_\")\n",
    "        if len(parts) == 2:\n",
    "            train_lang, test_lang = parts\n",
    "        else:\n",
    "            train_lang, test_lang = \"unknown\", \"unknown\"\n",
    "\n",
    "        df = pd.read_csv(file_path, sep=\"\\t\")\n",
    "\n",
    "        if  \"accuracy\" not in df.columns:\n",
    "            print(f\"Skipping {file_path}, missing expected columns.\")\n",
    "            continue\n",
    "\n",
    "        accuracy = df[\"accuracy\"].iloc[0]\n",
    "\n",
    "        rows.append({\n",
    "            \"Model\": model_name,\n",
    "            \"Train_Lang\": train_lang,\n",
    "            \"Test_Lang\": test_lang,\n",
    "            \"Accuracy\": accuracy\n",
    "        })\n",
    "\n",
    "summary_df = pd.DataFrame(rows)\n",
    "\n",
    "summary_df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"Summary table saved to {output_csv}\")\n",
    "print(summary_df)\n",
    "\n",
    "# To Latex table\n",
    "input_csv = output_csv\n",
    "output_txt = os.path.join(base_dir, \"summary_accuracy_table.txt\")\n",
    "\n",
    "df = pd.read_csv(input_csv)\n",
    "\n",
    "train_lang_labels = {\n",
    "    \"fon\": \"Fon\",\n",
    "    \"all\": \"Combined four languages\",\n",
    "}\n",
    "\n",
    "test_langs = sorted(df[\"Test_Lang\"].unique())\n",
    "\n",
    "models = df[\"Model\"].unique()\n",
    "\n",
    "lines = []\n",
    "header = \"Model & Train Data & \" + \" & \".join(test_langs) + \" \\\\\\\\\"\n",
    "lines.append(header)\n",
    "lines.append(\"\\\\hline\")\n",
    "\n",
    "for model in models:\n",
    "    model_df = df[df[\"Model\"] == model]\n",
    "    \n",
    "    train_conditions = [\n",
    "        (\"target\", \"Target language\"),\n",
    "        (\"fon\", train_lang_labels.get(\"fon\")),\n",
    "        (\"all\", train_lang_labels.get(\"all\"))\n",
    "    ]\n",
    "\n",
    "    for i, (cond_key, display_train) in enumerate(train_conditions):\n",
    "        if cond_key == \"target\":\n",
    "            # Select rows where train_lang == test_lang\n",
    "            sub_df = model_df[model_df[\"Train_Lang\"] == model_df[\"Test_Lang\"]]\n",
    "        else:\n",
    "            sub_df = model_df[model_df[\"Train_Lang\"] == cond_key]\n",
    "\n",
    "        if display_train is None:\n",
    "            display_train = cond_key.capitalize()\n",
    "\n",
    "        accuracies = []\n",
    "        for test_lang in test_langs:\n",
    "            match = sub_df[sub_df[\"Test_Lang\"] == test_lang]\n",
    "            if not match.empty:\n",
    "                accuracy = match[\"Accuracy\"].values[0] * 100\n",
    "                accuracies.append(f\"{accuracy:.2f}\\%\")\n",
    "            else:\n",
    "                accuracies.append(\"-\")\n",
    "\n",
    "        model_display = model if i == 0 else \"\"\n",
    "        line = f\"{model_display:<15} & {display_train:<30} & \" + \" & \".join(accuracies) + \" \\\\\\\\\"\n",
    "        lines.append(line)\n",
    "\n",
    "with open(output_txt, \"w\") as f:\n",
    "    f.write(\"\\n\".join(lines))\n",
    "\n",
    "print(f\"\\n LaTeX table saved to {output_txt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "base_dir = \"/Users/huxiyan/Desktop/H/25Fall/COSC426/Dione-Midterm-Replication-/results\"\n",
    "\n",
    "rows = []\n",
    "\n",
    "for model_name in os.listdir(base_dir):\n",
    "    model_path = os.path.join(base_dir, model_name)\n",
    "    if not os.path.isdir(model_path):\n",
    "        continue\n",
    "\n",
    "    for file_name in os.listdir(model_path):\n",
    "        if not file_name.endswith(\".tsv\"):\n",
    "            continue\n",
    "\n",
    "        file_path = os.path.join(model_path, file_name)\n",
    "\n",
    "        parts = file_name.replace(\"_results_bycond.tsv\", \"\").split(\"_\")\n",
    "        if len(parts) == 2:\n",
    "            train_lang, test_lang = parts\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        df = pd.read_csv(file_path, sep=\"\\t\")\n",
    "\n",
    "        df[\"Model\"] = model_name\n",
    "        df[\"Train_Lang\"] = train_lang\n",
    "        df[\"Test_Lang\"] = test_lang\n",
    "\n",
    "        rows.append(df)\n",
    "\n",
    "combined_df = pd.concat(rows, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nf/r2gt2wsd5pnb2cqvrbrw75t40000gn/T/ipykernel_33541/1204666713.py:29: FutureWarning: \n",
      "\n",
      "The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.\n",
      "\n",
      "  ax = sns.barplot(\n",
      "/var/folders/nf/r2gt2wsd5pnb2cqvrbrw75t40000gn/T/ipykernel_33541/1204666713.py:29: FutureWarning: \n",
      "\n",
      "The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.\n",
      "\n",
      "  ax = sns.barplot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved figure: /Users/huxiyan/Desktop/H/25Fall/COSC426/Dione-Midterm-Replication-/results/figures/macro-precision.png\n",
      "Saved figure: /Users/huxiyan/Desktop/H/25Fall/COSC426/Dione-Midterm-Replication-/results/figures/macro-recall.png\n",
      "Saved figure: /Users/huxiyan/Desktop/H/25Fall/COSC426/Dione-Midterm-Replication-/results/figures/macro-f1.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nf/r2gt2wsd5pnb2cqvrbrw75t40000gn/T/ipykernel_33541/1204666713.py:29: FutureWarning: \n",
      "\n",
      "The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.\n",
      "\n",
      "  ax = sns.barplot(\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "metrics = [\"macro-precision\", \"macro-recall\", \"macro-f1\"]\n",
    "\n",
    "output_fig_dir = os.path.join(base_dir, \"figures\")\n",
    "os.makedirs(output_fig_dir, exist_ok=True)\n",
    "\n",
    "# Define the desired order for the bars\n",
    "desired_order = [\n",
    "    \"ibo→ibo\", \"kin→kin\", \"sna→sna\",\n",
    "    \"fon→ibo\", \"fon→kin\", \"fon→sna\",\n",
    "    \"all→ibo\", \"all→kin\", \"all→sna\"\n",
    "]\n",
    "\n",
    "combined_df[\"Train→Test\"] = combined_df[\"Train_Lang\"] + \"→\" + combined_df[\"Test_Lang\"]\n",
    "\n",
    "combined_df[\"Train→Test\"] = pd.Categorical(\n",
    "    combined_df[\"Train→Test\"],\n",
    "    categories=desired_order,\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "sns.set(style=\"whitegrid\", context=\"talk\", font_scale=1.2)\n",
    "\n",
    "for metric in metrics:\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    \n",
    "    ax = sns.barplot(\n",
    "        data=combined_df,\n",
    "        x=\"Train→Test\",\n",
    "        y=metric,\n",
    "        hue=\"Model\",\n",
    "        ci=None,\n",
    "        palette=\"Set2\"\n",
    "    )\n",
    "    \n",
    "    ax.set_title(f\"{metric} for all Train/Test pairs\", fontsize=18, weight='bold')\n",
    "    ax.set_xlabel(\"Train → Test language\", fontsize=14)\n",
    "    ax.set_ylabel(metric.replace(\"-\", \" \").title(), fontsize=14)\n",
    "    \n",
    "    plt.xticks(rotation=45, ha=\"right\", fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.legend(title=\"Model\", fontsize=12, title_fontsize=13, loc=\"upper right\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.tight_layout()\n",
    "    fig_path = os.path.join(output_fig_dir, f\"{metric}.png\")\n",
    "    plt.savefig(fig_path, dpi=300)\n",
    "    print(f\"Saved figure: {fig_path}\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved combined results to /Users/huxiyan/Desktop/H/25Fall/COSC426/Dione-Midterm-Replication-/results/summary_bytokentype.csv\n",
      "LaTeX table saved to /Users/huxiyan/Desktop/H/25Fall/COSC426/Dione-Midterm-Replication-/results/summary_bytokentype_table.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "base_dir = \"/Users/huxiyan/Desktop/H/25Fall/COSC426/Dione-Midterm-Replication-/results\"\n",
    "output_csv = os.path.join(base_dir, \"summary_bytokentype.csv\")\n",
    "output_tex = os.path.join(base_dir, \"summary_bytokentype_table.txt\")\n",
    "\n",
    "rows = []\n",
    "\n",
    "for model_name in os.listdir(base_dir):\n",
    "    model_path = os.path.join(base_dir, model_name)\n",
    "    if not os.path.isdir(model_path):\n",
    "        continue\n",
    "\n",
    "    for file_name in os.listdir(model_path):\n",
    "        if not file_name.endswith(\"_results_bytokentype.tsv\"):\n",
    "            continue\n",
    "\n",
    "        file_path = os.path.join(model_path, file_name)\n",
    "\n",
    "        parts = file_name.replace(\"_results_bytokentype.tsv\", \"\").split(\"_\")\n",
    "        if len(parts) == 2:\n",
    "            train_lang, test_lang = parts\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        df = pd.read_csv(file_path, sep=\"\\t\")\n",
    "\n",
    "        if not {\"target_class\", \"precision\", \"recall\", \"f1\"}.issubset(df.columns):\n",
    "            print(f\"Skipping {file_path}, missing expected columns.\")\n",
    "            continue\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            rows.append({\n",
    "                \"Model\": model_name,\n",
    "                \"Train_Lang\": train_lang,\n",
    "                \"Test_Lang\": test_lang,\n",
    "                \"Target_Class\": row[\"target_class\"],\n",
    "                \"Precision\": row[\"precision\"],\n",
    "                \"Recall\": row[\"recall\"],\n",
    "                \"F1\": row[\"f1\"]\n",
    "            })\n",
    "\n",
    "summary_df = pd.DataFrame(rows)\n",
    "summary_df.to_csv(output_csv, index=False)\n",
    "print(f\"Saved combined results to {output_csv}\")\n",
    "\n",
    "models = sorted(summary_df[\"Model\"].unique())\n",
    "token_classes = sorted(summary_df[\"Target_Class\"].unique())\n",
    "\n",
    "lines = []\n",
    "header_parts = [\"Token Class\"]\n",
    "for model in models:\n",
    "    header_parts.extend([f\"{model} Prec.\", f\"{model} Rec.\", f\"{model} F1\"])\n",
    "header = \" & \".join(header_parts) + \" \\\\\\\\\"\n",
    "lines.append(header)\n",
    "lines.append(\"\\\\hline\")\n",
    "\n",
    "for token in token_classes:\n",
    "    row_parts = [token]\n",
    "    for model in models:\n",
    "        sub_df = summary_df[(summary_df[\"Model\"] == model) &\n",
    "                            (summary_df[\"Target_Class\"] == token)]\n",
    "        if sub_df.empty:\n",
    "            row_parts.extend([\"-\", \"-\", \"-\"])\n",
    "        else:\n",
    "            precision = sub_df[\"Precision\"].mean()\n",
    "            recall = sub_df[\"Recall\"].mean()\n",
    "            f1 = sub_df[\"F1\"].mean()\n",
    "            row_parts.extend([f\"{precision:.4f}\", f\"{recall:.4f}\", f\"{f1:.4f}\"])\n",
    "    line = \" & \".join(row_parts) + \" \\\\\\\\\"\n",
    "    lines.append(line)\n",
    "\n",
    "with open(output_tex, \"w\") as f:\n",
    "    f.write(\"\\n\".join(lines))\n",
    "\n",
    "print(f\"LaTeX table saved to {output_tex}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LaTeX F1 table by Test_Lang saved for afrolm\n",
      "LaTeX F1 table by Test_Lang saved for xlm-r\n"
     ]
    }
   ],
   "source": [
    "output_dir = os.path.join(base_dir, \"by_testlang_tables\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for model in [\"afrolm\", \"xlm-r\"]:\n",
    "    model_df = summary_df[summary_df[\"Model\"].str.lower() == model]\n",
    "    if model_df.empty:\n",
    "        print(f\"No data found for model {model}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    pivot_df = model_df.groupby([\"Test_Lang\", \"Target_Class\"])[\"F1\"].mean().reset_index()\n",
    "    pivot_df = pivot_df.pivot(index=\"Test_Lang\", columns=\"Target_Class\", values=\"F1\").fillna(\"-\")\n",
    "\n",
    "    token_classes = list(pivot_df.columns)\n",
    "    lines = []\n",
    "\n",
    "    header = \"Test Lang & \" + \" & \".join(token_classes) + \" \\\\\\\\\"\n",
    "    lines.append(header)\n",
    "    lines.append(\"\\\\hline\")\n",
    "\n",
    "    for test_lang, row in pivot_df.iterrows():\n",
    "        values = []\n",
    "        for token in token_classes:\n",
    "            val = row[token]\n",
    "            if isinstance(val, str):\n",
    "                values.append(\"-\")\n",
    "            else:\n",
    "                values.append(f\"{val:.4f}\")\n",
    "        line = f\"{test_lang} & \" + \" & \".join(values) + \" \\\\\\\\\"\n",
    "        lines.append(line)\n",
    "\n",
    "    output_tex_model = os.path.join(output_dir, f\"{model}_by_testlang_f1_table.txt\")\n",
    "    with open(output_tex_model, \"w\") as f:\n",
    "        f.write(\"\\n\".join(lines))\n",
    "\n",
    "    print(f\"LaTeX F1 table by Test_Lang saved for {model}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
